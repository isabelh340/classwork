   #alternate Edit this page Wikipedia (en) alternate copyright Wikipedia
   Atom feed

Logic programming

   From Wikipedia, the free encyclopedia
   Jump to: navigation, search
             Programming paradigms
     * Action
     * Agent-oriented
     * Aspect-oriented
     * Automata-based
     * Concurrent computing
          + Relativistic programming
     * Data-driven
     * Declarative (contrast: Imperative)
          + Constraint
          + Dataflow
               o Flow-based
               o Cell-oriented (spreadsheets)
               o Reactive
          + Functional
               o Functional logic
          + Logic
               o Abductive logic
               o Answer set
               o Constraint logic
               o Functional logic
               o Inductive logic
     * End-user programming
     * Event-driven
          + Service-oriented
          + Time-driven
     * Expression-oriented
     * Feature-oriented
     * Function-level (contrast: Value-level)
     * Generic
     * Imperative (contrast: Declarative)
          + Procedural
     * Language-oriented
          + Natural language programming
          + Discipline-specific
          + Domain-specific
          + Grammar-oriented
               o Dialecting
          + Intentional
     * Metaprogramming
          + Automatic
          + Reflective
               o Attribute-oriented
          + Homoiconic
          + Template
               o Policy-based
     * Non-structured (contrast: Structured)
          + Array
     * Nondeterministic
     * Parallel computing
          + Process-oriented
     * Point-free style
          + Concatenative
     * Semantic
     * Structured (contrast: Non-structured)
          + Block-structured
          + Modular (contrast: Monolithic)
          + Object-oriented (OOP)
               o By separation of concerns:
                    # Aspect-oriented
                    # Role-oriented
                    # Subject-oriented
               o Class-based
               o Prototype-based
          + Recursive
     * Value-level (contrast: Function-level)
     * Probabilistic
     * Concept

     * v
     * t
     * e

   Logic programming is a programming paradigm based on formal logic. A
   program written in a logic programming language is a set of sentences
   in logical form, expressing facts and rules about some problem domain.
   Major logic programming language families include Prolog, Answer set
   programming (ASP) and Datalog. In all of these languages, rules are
   written in the form of clauses:

          H :- B[1], …, B[n].

   and are read declaratively as logical implications:

          H if B[1] and … and B[n].

   H is called the head of the rule and B[1], …, B[n] is called the body.
   Facts are rules that have no body, and are written in the simplified
   form:

          H.

   In the simplest case in which H, B[1], …, B[n] are all atomic formulae,
   these clauses are called definite clauses or Horn clauses. However,
   there exist many extensions of this simple case, the most important one
   being the case in which conditions in the body of a clause can also be
   negations of atomic formulae. Logic programming languages that include
   this extension have the knowledge representation capabilities of a
   non-monotonic logic.

   In ASP and Datalog, logic programs have only a declarative reading, and
   their execution is performed by means of a proof procedure or model
   generator whose behaviour is not meant to be under the control of the
   programmer. However, in the Prolog family of languages, logic programs
   also have a procedural interpretation as goal-reduction procedures:

          to solve H, solve B[1], and ... and solve B[n].

   Consider, for example, the following clause:

          fallible(X) :- human(X).

   based on an example used by Terry Winograd ^[1] to illustrate the
   programming language Planner. As a clause in a logic program, it can be
   used both as a procedure to test whether X is fallible by testing
   whether X is human, and as a procedure to find an X that is fallible by
   finding an X that is human. Even facts have a procedural
   interpretation. For example, the clause:

          human(socrates).

   can be used both as a procedure to show that socrates is human, and as
   a procedure to find an X that is human by "assigning"socrates to X.

   The declarative reading of logic programs can be used by a programmer
   to verify their correctness. Moreover, logic-based program
   transformation techniques can also be used to transform logic programs
   into logically equivalent programs that are more efficient. In the
   Prolog family of logic programming languages, the programmer can also
   use the known problem-solving behaviour of the execution mechanism to
   improve the efficiency of programs.

Contents

     * 1 History
     * 2 Concepts
          + 2.1 Problem solving
          + 2.2 Negation as failure
          + 2.3 Knowledge representation
     * 3 Variants and extensions
          + 3.1 Prolog
          + 3.2 Abductive logic programming
          + 3.3 Metalogic programming
          + 3.4 Constraint logic programming
          + 3.5 Concurrent logic programming
          + 3.6 Concurrent constraint logic programming
          + 3.7 Inductive logic programming
          + 3.8 Higher-order logic programming
          + 3.9 Linear logic programming
          + 3.10 Object-oriented logic programming
          + 3.11 Transaction logic programming
     * 4 See also
     * 5 References
          + 5.1 General introductions
          + 5.2 Other sources
     * 6 Further reading
     * 7 External links

History[edit]

   The use of mathematical logic to represent and execute computer
   programs is also a feature of the lambda calculus, developed by Alonzo
   Church in the 1930s. However, the first proposal to use the clausal
   form of logic for representing computer programs was made by Cordell
   Green ^[2]. This used an axiomatization of a subset of LISP, together
   with a representation of an input-output relation, to compute the
   relation by simulating the execution of the program in LISP. Foster and
   Elcock's Absys, on the other hand, employed a combination of equations
   and lambda calculus in an assertional programming language which places
   no constraints on the order in which operations are performed ^[3].

   Logic programming in its present form can be traced back to debates in
   the late 1960s and early 1970s about declarative versus procedural
   representations of knowledge in Artificial Intelligence. Advocates of
   declarative representations were notably working at Stanford,
   associated with John McCarthy, Bertram Raphael and Cordell Green, and
   in Edinburgh, with John Alan Robinson (an academic visitor from
   Syracuse University), Pat Hayes, and Robert Kowalski. Advocates of
   procedural representations were mainly centered at MIT, under the
   leadership of Marvin Minsky and Seymour Papert.^[citation needed]

   Although it was based on the proof methods of logic, Planner, developed
   at MIT, was the first language to emerge within this proceduralist
   paradigm ^[4]. Planner featured pattern-directed invocation of
   procedural plans from goals (i.e. goal-reduction or backward chaining)
   and from assertions (i.e. forward chaining). The most influential
   implementation of Planner was the subset of Planner, called
   Micro-Planner, implemented by Gerry Sussman, Eugene Charniak and Terry
   Winograd. It was used to implement Winograd's natural-language
   understanding program SHRDLU, which was a landmark at that time ^[1].
   To cope with the very limited memory systems at the time, Planner used
   a backtracking control structure so that only one possible computation
   path had to be stored at a time. Planner gave rise to the programming
   languages QA-4, Popler, Conniver, QLISP, and the concurrent language
   Ether.^[citation needed]

   Hayes and Kowalski in Edinburgh tried to reconcile the logic-based
   declarative approach to knowledge representation with Planner's
   procedural approach. Hayes (1973) developed an equational language,
   Golux, in which different procedures could be obtained by altering the
   behavior of the theorem prover ^[5]. Kowalski, on the other hand,
   showed how SL-resolution ^[6] treats implications as goal-reduction
   procedures.^[7] Kowalski collaborated with Colmerauer in Marseille, who
   developed these ideas in the design and implementation of the
   programming language Prolog. Prolog gave rise to the programming
   languages ALF, Fril, Gödel, Mercury, Oz, Ciao, Visual Prolog, XSB, and
   λProlog, as well as a variety of concurrent logic programming
   languages, ^[8] constraint logic programming languages and
   datalog.^[citation needed]

   The Association for Logic Programming was founded to promote Logic
   Programming in 1986.

Concepts[edit]

Problem solving[edit]

   In the simplified, propositional case in which a logic program and a
   top-level atomic goal contain no variables, backward reasoning
   determines an and-or tree, which constitutes the search space for
   solving the goal. The top-level goal is the root of the tree. Given any
   node in the tree and any clause whose head matches the node, there
   exists a set of child nodes corresponding to the sub-goals in the body
   of the clause. These child nodes are grouped together by an "and". The
   alternative sets of children corresponding to alternative ways of
   solving the node are grouped together by an "or".

   Any search strategy can be used to search this space. Prolog uses a
   sequential, last-in-first-out, backtracking strategy, in which only one
   alternative and one sub-goal is considered at a time. Other search
   strategies, such as parallel search, intelligent backtracking, or
   best-first search to find an optimal solution, are also possible.

   In the more general case, where sub-goals share variables, other
   strategies can be used, such as choosing the subgoal that is most
   highly instantiated or that is sufficiently instantiated so that only
   one procedure applies. Such strategies are used, for example, in
   concurrent logic programming.

   The fact that there are alternative ways of executing a logic program
   has been characterised by the slogan

          Algorithm = Logic + Control

   where "Logic" represents a logic program and "Control" represents
   different theorem-proving strategies.^[9]

Negation as failure[edit]

   Main article: Negation as failure

   For most practical applications, as well as for applications that
   require non-monotonic reasoning in artificial intelligence, Horn clause
   logic programs need to be extended to normal logic programs, with
   negative conditions. A clause in a normal logic program has the form:

          H :- A[1], …, A[n], not B[1], …, not B[n].

   and is read declaratively as a logical implication:

          H if A[1] and … and A[n] and not B[1] and … and not B[n].

   where H and all the A[i] and B[i] are atomic formulas. The negation in
   the negative literals not B[i] is commonly referred to as "negation as
   failure", because in most implementations, a negative condition not
   B[i]is shown to hold by showing that the positive condition B[i] fails
   to hold. For example:

          canfly(X) :- bird(X), not abnormal(X).
          abnormal(X) :- wounded(X).
          bird(john).
          bird(mary).
          wounded(john).

   Given the goal of finding something that can fly:

          :- canfly(X).

   there are two candidate solutions, which solve the first subgoal
   bird(X), namely X = john and X = mary. The second subgoal not
   abnormal(john) of the first candidate solution fails, because
   wounded(john) succeeds and therefore abnormal(john) succeeds. However,
   The second subgoal not abnormal(mary) of the second candidate solution
   succeeds, because wounded(mary) fails and therefore abnormal(mary)
   fails. Therefore X = mary is the only solution of the goal.

   Micro-Planner had a construct, called "thnot", which when applied to an
   expression returns the value true if (and only if) the evaluation of
   the expression fails. An equivalent operator is normally built-in in
   modern Prolog's implementations. It is normally written as not(Goal) or
   \+ Goal, where Goal is some goal (proposition) to be proved by the
   program. This operator differs from negation in first-order logic: a
   negation such as \+ X == 1 fails when the variable X has been bound to
   the atom 1, but it succeeds in all other cases, including when X is
   unbound. This makes Prolog's reasoning non-monotonic: X = 1, \+ X == 1
   always fails, while \+ X == 1, X = 1 can succeed, binding X to 1,
   depending on whether X was initially bound (note that standard Prolog
   executes goals in left-to-right order).

   The logical status of negation as failure was unresolved until Keith
   Clark [1978] showed that, under certain natural conditions, it is a
   correct (and sometimes complete) implementation of classical negation
   with respect to the completion of the program. Completion amounts
   roughly to regarding the set of all the program clauses with the same
   predicate on the left hand side, say

          H :- Body[1].
          …
          H :- Body[k].

   as a definition of the predicate

          H iff (Body[1] or … or Body[k])

   where "iff" means "if and only if". Writing the completion also
   requires explicit use of the equality predicate and the inclusion of a
   set of appropriate axioms for equality. However, the implementation of
   negation by failure needs only the if-halves of the definitions without
   the axioms of equality.

   For example the completion of the program above is:

          canfly(X) iff bird(X), not abnormal(X).
          abnormal(X) iff wounded(X).
          bird(X) iff X = john or X = mary.
          X = X.
          not john = mary.
          not mary = john.

   The notion of completion is closely related to McCarthy's
   circumscription semantics for default reasoning, and to the closed
   world assumption.

   As an alternative to the completion semantics, negation as failure can
   also be interpreted epistemically, as in the stable model semantics of
   answer set programming. In this interpretation not(B[i]) means
   literally that B[i] is not known or not believed. The epistemic
   interpretation has the advantage that it can be combined very simply
   with classical negation, as in "extended logic programming", to
   formalise such phrases as "the contrary can not be shown", where
   "contrary" is classical negation and "can not be shown" is the
   epistemic interpretation of negation as failure.

Knowledge representation[edit]

   The fact that Horn clauses can be given a procedural interpretation
   and, vice versa, that goal-reduction procedures can be understood as
   Horn clauses + backward reasoning means that logic programs combine
   declarative and procedural representations of knowledge. The inclusion
   of negation as failure means that logic programming is a kind of
   non-monotonic logic.

   Despite its simplicity compared with classical logic, this combination
   of Horn clauses and negation as failure has proved to be surprisingly
   expressive. For example, it has been shown to correspond, with some
   further extensions, quite naturally to the semi-formal language of
   legislation. It is also a natural language for expressing common-sense
   laws of cause and effect, as in the situation calculus and event
   calculus.

Variants and extensions[edit]

Prolog[edit]

   Main article: Prolog

   The programming language Prolog was developed in 1972 by Alain
   Colmerauer. It emerged from a collaboration between Colmerauer in
   Marseille and Robert Kowalski in Edinburgh. Colmerauer was working on
   natural language understanding, using logic to represent semantics and
   using resolution for question-answering. During the summer of 1971,
   Colmerauer and Kowalski discovered that the clausal form of logic could
   be used to represent formal grammars and that resolution theorem
   provers could be used for parsing. They observed that some theorem
   provers, like hyper-resolution, behave as bottom-up parsers and others,
   like SL-resolution (1971), behave as top-down parsers.

   It was in the following summer of 1972, that Kowalski, again working
   with Colmerauer, developed the procedural interpretation of
   implications. This dual declarative/procedural interpretation later
   became formalised in the Prolog notation

          H :- B[1], …, B[n].

   which can be read (and used) both declaratively and procedurally. It
   also became clear that such clauses could be restricted to definite
   clauses or Horn clauses, where H, B[1], …, B[n] are all atomic
   predicate logic formulae, and that SL-resolution could be restricted
   (and generalised) to LUSH or SLD-resolution. Kowalski's procedural
   interpretation and LUSH were described in a 1973 memo, published in
   1974.

   Colmerauer, with Philippe Roussel, used this dual interpretation of
   clauses as the basis of Prolog, which was implemented in the summer and
   autumn of 1972. The first Prolog program, also written in 1972 and
   implemented in Marseille, was a French question-answering system. The
   use of Prolog as a practical programming language was given great
   momentum by the development of a compiler by David Warren in Edinburgh
   in 1977. Experiments demonstrated that Edinburgh Prolog could compete
   with the processing speed of other symbolic programming languages such
   as Lisp. Edinburgh Prolog became the de facto standard and strongly
   influenced the definition of ISO standard Prolog.

Abductive logic programming[edit]

   Abductive logic programming is an extension of normal Logic Programming
   that allows some predicates, declared as abducible predicates, to be
   "open" or undefined. A clause in an abductive logic program has the
   form:

          H :- B[1], …, B[n], A[1], …, A[n].

   where H is an atomic formula that is not abducible, all the B[i] are
   literals whose predicates are not abducible, and the A[i] are atomic
   formulas whose predicates are abducible. The abducible predicates can
   be constrained by integrity constraints, which can have the form:

          false :- B[1], …, B[n].

   where the B[i] are arbitrary literals (defined or abducible, and atomic
   or negated). For example:

          canfly(X) :- bird(X), normal(X).
          false :- normal(X), wounded(X).
          bird(john).
          bird(mary).
          wounded(john).

   where the predicate normal is abducible.

   Problem solving is achieved by deriving hypotheses expressed in terms
   of the abducible predicates as solutions of problems to be solved.
   These problems can be either observations that need to be explained (as
   in classical abductive reasoning) or goals to be solved (as in normal
   logic programming). For example, the hypothesis normal(mary) explains
   the observation canfly(mary). Moreover, the same hypothesis entails the
   only solution X = mary of the goal of finding something that can fly:

          :- canfly(X).

   Abductive logic programming has been used for fault diagnosis,
   planning, natural language processing and machine learning. It has also
   been used to interpret Negation as Failure as a form of abductive
   reasoning.

Metalogic programming[edit]

   Because mathematical logic has a long tradition of distinguishing
   between object language and metalanguage, logic programming also allows
   metalevel programming. The simplest metalogic program is the so-called
   "vanilla" meta-interpreter:
   solve(true).
   solve((A,B)):- solve(A),solve(B).
   solve(A):- clause(A,B),solve(B).

   where true represents an empty conjunction, and clause(A,B) means there
   is an object-level clause of the form A :- B.

   Metalogic programming allows object-level and metalevel representations
   to be combined, as in natural language. It can also be used to
   implement any logic that is specified by means of inference rules.

Constraint logic programming[edit]

   Main article: Constraint logic programming

   Constraint logic programming combines Horn clause logic programming
   with constraint solving. It extends Horn clauses by allowing some
   predicates, declared as constraint predicates, to occur as literals in
   the body of clauses. A constraint logic program is a set of clauses of
   the form:

          H :- C[1], …, C[n] \Diamond B[1], …, B[n].

   where H and all the B[i] are atomic formulas, and the C[i] are
   constraints. Declaratively, such clauses are read as ordinary logical
   implications:

          H if C[1] and … and C[n] and B[1] and … and B[n].

   However, whereas the predicates in the heads of clauses are defined by
   the constraint logic program, the predicates in the constraints are
   predefined by some domain-specific model-theoretic structure or theory.

   Procedurally, subgoals whose predicates are defined by the program are
   solved by goal-reduction, as in ordinary logic programming, but
   constraints are checked for satisfiability by a domain-specific
   constraint-solver, which implements the semantics of the constraint
   predicates. An initial problem is solved by reducing it to a
   satisfiable conjunction of constraints.

   The following constraint logic program represents a toy temporal
   database of john's history as a teacher:

          teaches(john, hardware, T) :- 1990 ≤ T, T < 1999.
          teaches(john, software, T) :- 1999 ≤ T, T < 2005.
          teaches(john, logic, T) :- 2005 ≤ T, T ≤ 2012.
          rank(john, instructor, T) :- 1990 ≤ T, T < 2010.
          rank(john, professor, T) :- 2010 ≤ T, T < 2014.

   Here ≤ and < are constraint predicates, with their usual intended
   semantics. The following goal clause queries the database to find out
   when john both taught logic and was a professor:

          :- teaches(john, logic, T), rank(john, professor, T).

   The solution is 2010 ≤ T, T ≤ 2012.

   Constraint logic programming has been used to solve problems in such
   fields as civil engineering, mechanical engineering, digital circuit
   verification, automated timetabling, air traffic control, and finance.
   It is closely related to abductive logic programming.

Concurrent logic programming[edit]

   Main article: Concurrent logic programming

   Concurrent logic programming integrates concepts of logic programming
   with concurrent programming. Its development was given a big impetus in
   the 1980s by its choice for the systems programming language of the
   Japanese Fifth Generation Project (FGCS) ^[10].

   A concurrent logic program is a set of guarded Horn clauses of the
   form:

                H :- G[1], …, G[n] | B[1], …, B[n].

   The conjunction G[1], … , G[n] is called the guard of the clause, and |
   is the commitment operator. Declaratively, guarded Horn clauses are
   read as ordinary logical implications:

                H if G[1] and … and G[n] and B[1] and … and B[n].

   However, procedurally, when there are several clauses whose heads H
   match a given goal, then all of the clauses are executed in parallel,
   checking whether their guards G[1], … , G[n] hold. If the guards of
   more than one clause hold, then a committed choice is made to one of
   the clauses, and execution proceedes with the subgoals B[1], …, B[n] of
   the chosen clause. These subgoals can also be executed in parallel.
   Thus concurrent logic programming implements a form of "don't care
   nondeterminism", rather than "don't know nondeterminism".

   For example, the following concurrent logic program defines a predicate
   shuffle(Left, Right, Merge) , which can be used to shuffle two lists
   Left and Right, combining them into a single list Merge that preserves
   the ordering of the two lists Left and Right:

          shuffle([], [], []).
          shuffle(Left, Right, Merge) :- Left = [First | Rest] | Merge =
          [First | ShortMerge], shuffle(Rest, Right, ShortMerge).
          shuffle(Left, Right, Merge) :- Right = [First | Rest] | Merge =
          [First | ShortMerge], shuffle(Left, Rest, ShortMerge).

   Here, [] represents the empty list, and [Head | Tail] represents a list
   with first element Head followed by list Tail, as in Prolog. (Notice
   that the first occurrence of | in the second and third clauses is the
   list constructor, whereas the second occurrence of | is the commitment
   operator.) The program can be used, for example, to shuffle the lists
   [ace, queen, king] and [1, 4, 2] by invoking the goal clause:

          shuffle([ace, queen, king], [1, 4, 2], Merge).

   The program will non-deterministically generate a single solution, for
   example Merge = [ace, queen, 1, king, 4, 2].

   Arguably, concurrent logic programming is based on message passing and
   consequently is subject to the same indeterminacy as other concurrent
   message-passing systems, such as Actors (see Indeterminacy in
   concurrent computation). Carl Hewitt^[citation needed] has argued that,
   concurrent logic programming is not based on logic in his sense that
   computational steps cannot be logically deduced [Hewitt and Agha,
   1988]. However, in concurrent logic programming, any result of a
   terminating computation is a logical consequence of the program, and
   any partial result of a partial computation is a logical consequence of
   the program and the residual goal (process network). Consequently, the
   indeterminacy of computations implies that not all logical consequences
   of the program can be deduced.^[neutrality is disputed]

Concurrent constraint logic programming[edit]

   Main article: Concurrent constraint logic programming

   Concurrent constraint logic programming combines concurrent logic
   programming and constraint logic programming, using constraints to
   control concurrency. A clause can contain a guard, which is a set of
   constraints that may block the applicability of the clause. When the
   guards of several clauses are satisfied, concurrent constraint logic
   programming makes a committed choice to the use of only one.

Inductive logic programming[edit]

   Main article: Inductive logic programming

   Inductive logic programming is concerned with generalizing positive and
   negative examples in the context of background knowledge: machine
   learning of logic programs. Recent work in this area, combining logic
   programming, learning and probability, has given rise to the new field
   of statistical relational learning and probabilistic inductive logic
   programming.

Higher-order logic programming[edit]

   Several researchers have extended logic programming with higher-order
   programming features derived from higher-order logic, such as predicate
   variables. Such languages include the Prolog extensions HiLog and
   λProlog.

Linear logic programming[edit]

   Basing logic programming within linear logic has resulted in the design
   of logic programming languages that are considerably more expressive
   than those based on classical logic. Horn clause programs can only
   represent state change by the change in arguments to predicates. In
   linear logic programming, one can use the ambient linear logic to
   support state change. Some early designs of logic programming languages
   based on linear logic include LO [Andreoli & Pareschi, 1991], Lolli
   ^[11], ACL ^[12], and Forum [Miller, 1996]. Forum provides a
   goal-directed interpretation of all of linear logic.

Object-oriented logic programming[edit]

   F-logic extends logic programming with objects and the frame syntax. A
   number of systems are based on F-logic, including Flora-2, FLORID, and
   a highly scalable commercial system Ontobroker.

Transaction logic programming[edit]

   Transaction logic is an extension of logic programming with a logical
   theory of state-modifying updates. It has both a model-theoretic
   semantics and a procedural one. An implementation of a subset of
   Transaction logic is available in the Flora-2 system. Other prototypes
   are also available.

See also[edit]

     * Boolean satisfiability problem
     * Constraint logic programming
     * Datalog
     * Functional programming
     * Inductive logic programming
     * Fuzzy logic
     * Logic in computer science (includes Formal methods)
     * Logic programming languages
     * Programming paradigm
     * R++
     * Reasoning system
     * Satisfiability

References[edit]

   This article includes a list of references, but its sources remain
   unclear because it has insufficient inline citations. Please help to
   improve this article by introducing more precise citations. (February
   2012)
    1. ^ ^a ^b T. Winograd (1972). "Understanding natural language".
       Cognitive psychology, 3 (1): 1–191.
    2. ^ Cordell Green. Application of Theorem Proving to Problem Solving
       IJCAI 1969.
    3. ^ J.M. Foster and E.W. Elcock. ABSYS 1: An Incremental Compiler for
       Assertions: an Introduction, Machine Intelligence 4, Edinburgh U
       Press, 1969, pp. 423–429
    4. ^ Carl Hewitt. Planner: A Language for Proving Theorems in Robots
       IJCAI 1969.
    5. ^ Pat Hayes. Computation and Deduction. In Proceedings of the 2nd
       MFCS Symposium. Czechoslovak Academy of Sciences, 1973,
       pp. 105–118.
    6. ^ Robert Kowalski and Donald and Kuehner, Linear Resolution with
       Selection Function Artificial Intelligence, Vol. 2, 1971,
       pp. 227–60.
    7. ^ Robert Kowalski Predicate Logic as a Programming Language Memo
       70, Department of Artificial Intelligence, Edinburgh University.
       1973. Also in Proceedings IFIP Congress, Stockholm, North Holland
       Publishing Co., 1974, pp. 569–574.
    8. ^ Ehud Shapiro. The family of concurrent logic programming
       languages ACM Computing Surveys. September 1989.
    9. ^ R.A.Kowalski (July 1979). "Algorithm=Logic + Control".
       Communications of the ACM 22 (7): 424–436.
       doi:10.1145/359131.359136.
   10. ^ Shunichi Uchida and Kazuhiro Fuchi Proceedings of the FGCS
       Project Evaluation Workshop Institute for New Generation Computer
       Technology (ICOT). 1992.
   11. ^ Joshua Hodas and Dale Miller. Logic Programming in a Fragment of
       Intuitionistic Linear Logic, Information and Computation, 1994,
       110(2), 327-365.
   12. ^ Naoki Kobayashi and Akinori Yonezawa. Asynchronous communication
       model based on linear logic, Formal Aspects of Computing, 1994,
       279-294.

General introductions[edit]

     * Chitta Baral and Michael Gelfond. Logic programming and knowledge
       representation Journal of Logic Programming. 1994, Vol. 19, 73-148.
     * Robert Kowalski. The Early Years of Logic Programming CACM. January
       1988.
     * J. W. Lloyd. Foundations of Logic Programming (2nd edition).
       Springer-Verlag 1987.

Other sources[edit]

     * John McCarthy. Programs with common sense Symposium on
       Mechanization of Thought Processes. National Physical Laboratory.
       Teddington, England. 1958.
     * D. Miller, G. Nadathur, F. Pfenning, A. Scedrov. Uniform proofs as
       a foundation for logic programming, Annals of Pure and Applied
       Logic, vol. 51, pp 125–157, 1991.
     * Ehud Shapiro (Editor). Concurrent Prolog MIT Press. 1987.
     * James Slagle. Experiments with a Deductive Question-Answering
       Program CACM. December 1965.

Further reading[edit]

     * Carl Hewitt. Procedural Embedding of Knowledge In Planner IJCAI
       1971.
     * Carl Hewitt. The repeated demise of logic programming and why it
       will be reincarnated What Went Wrong and Why: Lessons from AI
       Research and Applications. Technical Report SS-06-08. AAAI Press.
       March 2006.
     * Evgeny Dantsin, Thomas Eiter, Georg Gottlob, Andrei Voronkov:
       Complexity and expressive power of logic programming. ACM Comput.
       Surv. 33(3): 374-425 (2001)
     * Ulf Nilsson and Jan Maluszynski, Logic, Programming and Prolog

External links[edit]

     * Logic Programming Virtual Library entry
     * Bibliographies on Logic Programming
     * Association for Logic Programming (ALP)
     * Theory and Practice of Logic Programming journal
     * Logic programming in C++ with Castor
     * Logic programming in Oz
     * Prolog Development Center
     * Racklog: Logic Programming in Racket


     * v
     * t
     * e

   Types of programming languages
     * Array
     * Aspect-oriented
     * Class-based
     * Concatenative
     * Concurrent
     * Data-structured
     * Dataflow
     * Declarative
     * Domain-specific
     * Dynamic
     * Esoteric
     * Event-driven
     * Extensible
     * Functional
     * Imperative
     * Logic
     * Macro
     * Metaprogramming
     * Multi-paradigm
     * Object-based
     * Object-oriented
     * Pipeline
     * Procedural
     * Prototype-based
     * Reflective
     * Rule-based
     * Scripting
     * Synchronous
     * Templating

     * Assembly
     * Compiled
     * Interpreted
     * Machine

     * Low-level
     * High-level
     * Very high-level

     * First generation
     * Second generation
     * Third generation
     * Fourth generation
     * Fifth generation

     * Non-English-based
     * Off-side rule
     * Visual


     * v
     * t
     * e

   Computable knowledge
   Topics and
   concepts
     * Alphabet of human thought
     * Authority control
     * Automated reasoning
     * Commonsense knowledge
     * Commonsense reasoning
     * Computability
     * Formal system
     * Inference engine
     * Knowledge base
     * Knowledge-based systems
     * Knowledge engineering
     * Knowledge extraction
     * Knowledge representation
     * Knowledge retrieval
     * Library classification
     * Logic programming
     * Ontology
     * Question answering
     * Semantic reasoner

   Proposals and
   implementations
     * Zairja
     * Ars Magna (Ramon Llull, 1300)
     * An Essay towards a Real Character and a Philosophical Language
       (John Wilkins, 1688)
     * Calculus ratiocinator & Characteristica universalis (Gottfried
       Wilhelm Leibniz, 1700)
     * Dewey Decimal Classification (Melvil Dewey, 1876)
     * Begriffsschrift (Gottlob Frege, 1879)
     * Mundaneum (Paul Otlet & Henri La Fontaine, 1910)
     * Logical atomism (Bertrand Russell, 1918)
     * Tractatus Logico-Philosophicus (Ludwig Wittgenstein, 1921)
     * Hilbert's program (David Hilbert, 1920s)
     * Incompleteness theorem (Kurt Gödel, 1931)
     * Memex (Vannevar Bush, 1945)
     * Prolog (1972)
     * Cyc (1984)
     * True Knowledge (Evi, 2007)
     * Wolfram Alpha (Wolfram Research, 2009)
     * Watson (IBM, 2011)
     * Siri (Apple, 2011)
     * Knowledge Graph (Google, 2012)

   In fiction
     * The Engine (Gulliver's Travels, 1726)
     * Joe ("A Logic Named Joe," 1946)
     * The Librarian (Snow Crash, 1992)
     * Dr. Know (A.I. Artificial Intelligence, 2001)
     * Waterhouse (The Baroque Cycle, 2003)

   Retrieved from
   "http://en.wikipedia.org/w/index.php?title=Logic_programming&oldid=6240
   87799"
   Categories:
     * 1972 introductions
     * Logic programming
     * Programming paradigms

   Hidden categories:
     * All articles with unsourced statements
     * Articles with unsourced statements from July 2013
     * Articles with unsourced statements from March 2014
     * All articles with minor POV problems
     * Articles with minor POV problems from August 2014
     * Articles lacking in-text citations from February 2012
     * All articles lacking in-text citations

Navigation menu

Personal tools

     * Create account
     * Log in

Namespaces

     * Article
     * Talk

Variants

Views

     * Read
     * Edit
     * View history

More

Search

   ____________________ Search Go

Navigation

     * Main page
     * Contents
     * Featured content
     * Current events
     * Random article
     * Donate to Wikipedia
     * Wikimedia Shop

Interaction

     * Help
     * About Wikipedia
     * Community portal
     * Recent changes
     * Contact page

Tools

     * What links here
     * Related changes
     * Upload file
     * Special pages
     * Permanent link
     * Page information
     * Wikidata item
     * Cite this page

Print/export

     * Create a book
     * Download as PDF
     * Printable version

Languages

     * العربية
     * বাংলা
     * Bosanski
     * Čeština
     * Deutsch
     * Eesti
     * Español
     * فارسی
     * Français
     * Gaeilge
     * Galego
     * 한국어
     * Hrvatski
     * Ido
     * Italiano
     * עברית
     * Bahasa Melayu
     * Nederlands
     * 日本語
     * Polski
     * Português
     * Русиньскый
     * Русский
     * Shqip
     * Suomi
     * Svenska
     * ไทย
     * Türkçe
     * Українська
     * Tiếng Việt
     * 中文
     *

   Edit links

     * This page was last modified on 4 September 2014 at 00:12.
     * Text is available under the Creative Commons Attribution-ShareAlike
       License; additional terms may apply. By using this site, you agree
       to the Terms of Use and Privacy Policy. Wikipedia® is a registered
       trademark of the Wikimedia Foundation, Inc., a non-profit
       organization.

     * Privacy policy
     * About Wikipedia
     * Disclaimers
     * Contact Wikipedia
     * Developers
     * Mobile view

     * Wikimedia Foundation
     * Powered by MediaWiki
